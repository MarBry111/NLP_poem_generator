{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e10cbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913baa3",
   "metadata": {},
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5044315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/gpt2/blame/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b58b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm a language model, I'm a problem solver in languages.\"\n",
      "\n",
      "At the same time, she said we can understand an\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "\n",
    "print( generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=1)[0]['generated_text'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee28683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_en = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6cfea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer_en(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b673a",
   "metadata": {},
   "source": [
    "### Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1a4539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pl = AutoModelWithLMHead.from_pretrained('flax-community/papuGaPT2')\n",
    "tokenizer_pl = AutoTokenizer.from_pretrained('flax-community/papuGaPT2')\n",
    "#set_seed(42) # reproducibility\n",
    "\n",
    "text = 'Największym polskim poetą był'\n",
    "input_ids = tokenizer_pl.encode(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91ab784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Największym polskim poetą był Czesław Bielecki.\n"
     ]
    }
   ],
   "source": [
    "sample_outputs = model_pl.generate(\n",
    "    input_ids,\n",
    "    do_sample=True, \n",
    "    max_length=10, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "print( tokenizer_pl.decode(sample_outputs[0], skip_special_tokens=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8dd7ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_generated_text(text, n_len=10, tokenizer=tokenizer_pl, model=model_pl):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "    sample_outputs = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True, \n",
    "        max_length=n_len, \n",
    "        top_k=20, \n",
    "        top_p=0.95, \n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    print( tokenizer.decode(sample_outputs[0], skip_special_tokens=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "180ce579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nad rzeczką opodal krzaczka\n",
      "Mieszkała kaczka-dziwaczka,\n",
      "Lecz zamiast trzymać się rzeczki\n",
      "Robiła piesze wycieczki.\n",
      "Nagle usłyszała odgłos kroków. Odgłos zbliżającej się ku nią kobiety. Nie było jej. Stanęła na\n",
      "W tej samej chwili, kiedy poczuła, że jej serce bije, na jej twarzy pojawiło się\n",
      "się małe czerwone, jakby z zaschniętych łez. Nie zdążyła nawet podnieść wzroku, zanim ujrzała\n",
      "Ach\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Nad rzeczką opodal krzaczka\n",
    "Mieszkała kaczka-dziwaczka,\n",
    "Lecz zamiast trzymać się rzeczki\n",
    "Robiła piesze wycieczki.\\n\"\"\"\n",
    "\n",
    "return_generated_text(text, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f75de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd5016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
